

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>brevitas.function package &mdash; Brevitas 0.2.0-alpha documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Brevitas
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">brevitas.function package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-brevitas.function.autograd_ops">brevitas.function.autograd_ops module</a></li>
<li><a class="reference internal" href="#module-brevitas.function.ops">brevitas.function.ops module</a></li>
<li><a class="reference internal" href="#module-brevitas.function.ops_ste">brevitas.function.ops_ste module</a></li>
<li><a class="reference internal" href="#module-brevitas.function.shape">brevitas.function.shape module</a></li>
<li><a class="reference internal" href="#module-brevitas.function">Module contents</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Brevitas</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>brevitas.function package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/brevitas.function.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="brevitas-function-package">
<h1>brevitas.function package<a class="headerlink" href="#brevitas-function-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-brevitas.function.autograd_ops">
<span id="brevitas-function-autograd-ops-module"></span><h2>brevitas.function.autograd_ops module<a class="headerlink" href="#module-brevitas.function.autograd_ops" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="brevitas.function.autograd_ops.binary_sign_ste_fn">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.function.autograd_ops.</code><code class="sig-name descname">binary_sign_ste_fn</code><a class="headerlink" href="#brevitas.function.autograd_ops.binary_sign_ste_fn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements binary_sign_ste with a straight through estimator</p>
<p>Look at the documentation of <a class="reference internal" href="#brevitas.function.ops_ste.binary_sign_ste" title="brevitas.function.ops_ste.binary_sign_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">binary_sign_ste()</span></code></a> for further details.</p>
<dl class="method">
<dt id="brevitas.function.autograd_ops.binary_sign_ste_fn.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_y</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.binary_sign_ste_fn.backward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="brevitas.function.autograd_ops.binary_sign_ste_fn.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.binary_sign_ste_fn.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="brevitas.function.autograd_ops.ceil_ste_fn">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.function.autograd_ops.</code><code class="sig-name descname">ceil_ste_fn</code><a class="headerlink" href="#brevitas.function.autograd_ops.ceil_ste_fn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements ceil_ste with a straight through estimator</p>
<p>Look at the documentation of <a class="reference internal" href="#brevitas.function.ops_ste.ceil_ste" title="brevitas.function.ops_ste.ceil_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">ceil_ste()</span></code></a> for further details.</p>
<dl class="method">
<dt id="brevitas.function.autograd_ops.ceil_ste_fn.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_y</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.ceil_ste_fn.backward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="brevitas.function.autograd_ops.ceil_ste_fn.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.ceil_ste_fn.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="brevitas.function.autograd_ops.floor_ste_fn">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.function.autograd_ops.</code><code class="sig-name descname">floor_ste_fn</code><a class="headerlink" href="#brevitas.function.autograd_ops.floor_ste_fn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements floor_ste with a straight through estimator</p>
<p>Look at the documentation of <a class="reference internal" href="#brevitas.function.ops_ste.floor_ste" title="brevitas.function.ops_ste.floor_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">floor_ste()</span></code></a> for further details.</p>
<dl class="method">
<dt id="brevitas.function.autograd_ops.floor_ste_fn.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_y</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.floor_ste_fn.backward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="brevitas.function.autograd_ops.floor_ste_fn.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.floor_ste_fn.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="brevitas.function.autograd_ops.round_ste_fn">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.function.autograd_ops.</code><code class="sig-name descname">round_ste_fn</code><a class="headerlink" href="#brevitas.function.autograd_ops.round_ste_fn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements round_ste with a straight through estimator</p>
<p>Look at the documentation of <a class="reference internal" href="#brevitas.function.ops_ste.round_ste" title="brevitas.function.ops_ste.round_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_ste()</span></code></a> for further details.</p>
<dl class="method">
<dt id="brevitas.function.autograd_ops.round_ste_fn.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_y</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.round_ste_fn.backward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="brevitas.function.autograd_ops.round_ste_fn.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.round_ste_fn.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="brevitas.function.autograd_ops.scalar_clamp_ste_fn">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.function.autograd_ops.</code><code class="sig-name descname">scalar_clamp_ste_fn</code><a class="headerlink" href="#brevitas.function.autograd_ops.scalar_clamp_ste_fn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements scalar_clamp with a straight through estimator</p>
<p>Look at the documentation of <a class="reference internal" href="#brevitas.function.ops_ste.scalar_clamp_ste" title="brevitas.function.ops_ste.scalar_clamp_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">scalar_clamp_ste()</span></code></a> for further details.</p>
<dl class="method">
<dt id="brevitas.function.autograd_ops.scalar_clamp_ste_fn.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_y</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.scalar_clamp_ste_fn.backward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="brevitas.function.autograd_ops.scalar_clamp_ste_fn.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">min_val</em>, <em class="sig-param">max_val</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.scalar_clamp_ste_fn.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="brevitas.function.autograd_ops.tensor_clamp_ste_fn">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.function.autograd_ops.</code><code class="sig-name descname">tensor_clamp_ste_fn</code><a class="headerlink" href="#brevitas.function.autograd_ops.tensor_clamp_ste_fn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements tensor_clamp with a straight through estimator</p>
<p>Look at the documentation of <a class="reference internal" href="#brevitas.function.ops_ste.tensor_clamp_ste" title="brevitas.function.ops_ste.tensor_clamp_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp_ste()</span></code></a> for further details.</p>
<dl class="method">
<dt id="brevitas.function.autograd_ops.tensor_clamp_ste_fn.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_y</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.tensor_clamp_ste_fn.backward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="brevitas.function.autograd_ops.tensor_clamp_ste_fn.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">min_val</em>, <em class="sig-param">max_val</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.tensor_clamp_ste_fn.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="brevitas.function.autograd_ops.ternary_sign_ste_fn">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.function.autograd_ops.</code><code class="sig-name descname">ternary_sign_ste_fn</code><a class="headerlink" href="#brevitas.function.autograd_ops.ternary_sign_ste_fn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements ternary_sign_ste with a straight through estimator</p>
<p>Look at the documentation of <a class="reference internal" href="#brevitas.function.ops_ste.ternary_sign_ste" title="brevitas.function.ops_ste.ternary_sign_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">ternary_sign_ste()</span></code></a> for further details.</p>
<dl class="method">
<dt id="brevitas.function.autograd_ops.ternary_sign_ste_fn.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_y</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.ternary_sign_ste_fn.backward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="brevitas.function.autograd_ops.ternary_sign_ste_fn.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ops.ternary_sign_ste_fn.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-brevitas.function.ops">
<span id="brevitas-function-ops-module"></span><h2>brevitas.function.ops module<a class="headerlink" href="#module-brevitas.function.ops" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="brevitas.function.ops.tensor_clamp">
<code class="sig-prename descclassname">brevitas.function.ops.</code><code class="sig-name descname">tensor_clamp</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">min_val</em>, <em class="sig-param">max_val</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops.tensor_clamp" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Tensor on which to apply the clamp operation</p></li>
<li><p><strong>min_val</strong> (<em>Tensor</em>) – Tensor containing the minimum values for the clamp operation. Must have the same shape of <cite>x</cite></p></li>
<li><p><strong>max_val</strong> (<em>Tensor</em>) – Tensor containing the maximum values for the clamp operation. Must have the same shape of <cite>x</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor for which every element of <cite>x</cite> is clamped between the corresponding minimum and maximum values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="brevitas.function.ops.max_uint">
<code class="sig-prename descclassname">brevitas.function.ops.</code><code class="sig-name descname">max_uint</code><span class="sig-paren">(</span><em class="sig-param">narrow_range</em>, <em class="sig-param">bit_width</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops.max_uint" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the maximum unsigned integer representable</p>
<p>The maximum unsigned integer representable depends on the number of bits, and whether the narrow range setting
is used. If so, the maximum value represented is decreased by one unit.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>narrow_range</strong> (<em>Bool</em>) – Flag that indicates whether to decrease the possible maximum value represented</p></li>
<li><p><strong>bit_width</strong> (<em>Tensor</em>) – Number of bits available for the representation</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Maximum unsigned integer that can be represented according to the input parameters</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="brevitas.function.ops.max_int">
<code class="sig-prename descclassname">brevitas.function.ops.</code><code class="sig-name descname">max_int</code><span class="sig-paren">(</span><em class="sig-param">signed</em>, <em class="sig-param">bit_width</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops.max_int" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the maximum integer representable</p>
<p>The maximum integer representable depends on the number of bits, and whether the negative numbers are included
in the representation. If so, one bit is lost in the computation of the maximum value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signed</strong> (<em>Bool</em>) – Flag that indicates whether negative numbers must be included or not</p></li>
<li><p><strong>bit_width</strong> (<em>Tensor</em>) – Number of bits available for the representation</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Maximum integer that can be represented according to the input parameters</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="brevitas.function.ops.min_int">
<code class="sig-prename descclassname">brevitas.function.ops.</code><code class="sig-name descname">min_int</code><span class="sig-paren">(</span><em class="sig-param">signed</em>, <em class="sig-param">narrow_range</em>, <em class="sig-param">bit_width</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops.min_int" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the minimum integer representable</p>
<p>The minimum integer representable depends on the number of bits, whether the negative numbers are included
in the representation, and whether the narrow range setting is used.
For positive-only number, the minimum value will always be zero.
If the sign and narrow range flags are both set, then the representation will be such that there is symmetry
between positive and negative values.
For example, for 3 bit representation, with sign and narrow range, the
values representable are in the range [-3, 3].
If the narrow range is not enabled, then the possible values will be in the range [-4, 3].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signed</strong> (<em>Bool</em>) – Flag that indicates whether negative numbers must be included or not</p></li>
<li><p><strong>narrow_range</strong> (<em>Bool</em>) – Flag that indicates whether the narrow range setting is enabled or not</p></li>
<li><p><strong>bit_width</strong> (<em>Tensor</em>) – Number of bits available for the representation</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Minimum integer that can be represented according to the input parameters</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-brevitas.function.ops_ste">
<span id="brevitas-function-ops-ste-module"></span><h2>brevitas.function.ops_ste module<a class="headerlink" href="#module-brevitas.function.ops_ste" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="brevitas.function.ops_ste.round_ste">
<code class="sig-prename descclassname">brevitas.function.ops_ste.</code><code class="sig-name descname">round_ste</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops_ste.round_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform round operation with Straight Trough Estimation (STE) of the Gradient</p>
<p>This operation behaves like an identity on the backward pass.
For Pytorch version &gt;= 1.3.0, the STE operator is implemented in C++ using the
torch::autograd::Function class and compiled. At execution time, the Just-In-Time (JIT) compiler of Pytorch
is used to speed-up the computation.
For Pytorch version &lt; 1.3.0, the STE operator is implemented using the
torch.autograd.Function class in python, and the JIT cannot be used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Tensor on which to apply the round operation</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor after applying round operation. When backpropagating through this value,
a straight through estimator is applied.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="brevitas.function.ops_ste.ceil_ste">
<code class="sig-prename descclassname">brevitas.function.ops_ste.</code><code class="sig-name descname">ceil_ste</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops_ste.ceil_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform ceil operation with Straight Trough Estimation (STE) of the Gradient</p>
<p>This operation behaves like an identity on the backward pass.
For Pytorch version &gt;= 1.3.0, the STE operator is implemented in C++ using the
torch::autograd::Function class and compiled. At execution time, the Just-In-Time (JIT) compiler of Pytorch
is used to speed-up the computation.
For Pytorch version &lt; 1.3.0, the STE operator is implemented using the
torch.autograd.Function class in python, and the JIT cannot be used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Tensor on which to apply the ceil operation</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor after applying ceil operation.
When backpropagating through this value, a straight through estimator is applied.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="brevitas.function.ops_ste.floor_ste">
<code class="sig-prename descclassname">brevitas.function.ops_ste.</code><code class="sig-name descname">floor_ste</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops_ste.floor_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform floor operation with Straight Trough Estimation (STE) of the Gradient</p>
<p>This operation behaves like an identity on the backward pass.
For Pytorch version &gt;= 1.3.0, the STE operator is implemented in C++ using the
torch::autograd::Function class and compiled. At execution time, the Just-In-Time (JIT) compiler of Pytorch
is used to speed-up the computation.
For Pytorch version &lt; 1.3.0, the STE operator is implemented using the
torch.autograd.Function class in python, and the JIT cannot be used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Tensor on which to apply the floor operation</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor after applying floor operation.
When backpropagating through this value, a straight through estimator is applied.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="brevitas.function.ops_ste.tensor_clamp_ste">
<code class="sig-prename descclassname">brevitas.function.ops_ste.</code><code class="sig-name descname">tensor_clamp_ste</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">min_val</em>, <em class="sig-param">max_val</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops_ste.tensor_clamp_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform tensor-clamp operation with Straight Trough Estimation (STE) of the Gradient</p>
<p>This function accepts two Tensors as <cite>min_val</cite> and <cite>max_val</cite>. These Tensors must have the same shape as
<cite>x</cite>, so that each element of <cite>x</cite> can be clamped according to the correspondent min_val and max_val.
This operation behaves like an identity on the backward pass.
For Pytorch version &gt;= 1.3.0, the STE operator is implemented in C++ using the
torch::autograd::Function class and compiled. At execution time, the Just-In-Time (JIT) compiler of Pytorch
is used to speed-up the computation.
For Pytorch version &lt; 1.3.0, the STE operator is implemented using the
torch.autograd.Function class in python, and the JIT cannot be used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Tensor on which to apply the clamp operation</p></li>
<li><p><strong>min_val</strong> (<em>Tensor</em>) – Tensor containing the minimum values for the clamp operation. Must have the same shape of <cite>x</cite></p></li>
<li><p><strong>max_val</strong> (<em>Tensor</em>) – Tensor containing the maximum values for the clamp operation. Must have the same shape of <cite>x</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor for which every element of <cite>x</cite> is clamped between the corresponding minimum and maximum values.
When backpropagating through this value, a straight through estimator is applied.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="brevitas.function.ops_ste.scalar_clamp_ste">
<code class="sig-prename descclassname">brevitas.function.ops_ste.</code><code class="sig-name descname">scalar_clamp_ste</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">min_val</em>, <em class="sig-param">max_val</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops_ste.scalar_clamp_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform clamp operation with Straight Trough Estimation (STE) of the Gradient</p>
<p>This operation behaves like an identity on the backward pass.
For Pytorch version &gt;= 1.3.0, the STE operator is implemented in C++ using the
torch::autograd::Function class and compiled. At execution time, the Just-In-Time (JIT) compiler of Pytorch
is used to speed-up the computation.
For Pytorch version &lt; 1.3.0, the STE operator is implemented using the
torch.autograd.Function class in python, and the JIT cannot be used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Tensor on which to apply the clamp operation</p></li>
<li><p><strong>min_val</strong> (<em>Float</em>) – Scalar containing the minimum value for the clamp operation</p></li>
<li><p><strong>max_val</strong> (<em>Float</em>) – Scalar containing the maximum value for the clamp operation</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor for which every element of <cite>x</cite> is clamped between <cite>min_val</cite> and <cite>max_val</cite>.
When backpropagating through this value, a straight through estimator is applied.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="brevitas.function.ops_ste.binary_sign_ste">
<code class="sig-prename descclassname">brevitas.function.ops_ste.</code><code class="sig-name descname">binary_sign_ste</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops_ste.binary_sign_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform binarization with Straight Trough Estimation (STE) of the Gradient</p>
<p>This operation performs binarization on the input Tensor.
The output value will be one for each input value &gt;= 0, otherwise it will be 0.
This operation behaves like an identity on the backward pass.
For Pytorch version &gt;= 1.3.0, the STE operator is implemented in C++ using the
torch::autograd::Function class and compiled. At execution time, the Just-In-Time (JIT) compiler of Pytorch
is used to speed-up the computation.
For Pytorch version &lt; 1.3.0, the STE operator is implemented using the
torch.autograd.Function class in python, and the JIT cannot be used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Tensor on which to apply the binarization operation</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor after applying binarization. When backpropagating through this value, a straight
through estimator is applied.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="brevitas.function.ops_ste.ternary_sign_ste">
<code class="sig-prename descclassname">brevitas.function.ops_ste.</code><code class="sig-name descname">ternary_sign_ste</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.ops_ste.ternary_sign_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform ternary operator with Straight Trough Estimation (STE) of the Gradient</p>
<p>This operations behaves as the function <cite>sign</cite> of Pytorch.
This operation behaves like an identity on the backward pass.
For Pytorch version &gt;= 1.3.0, the STE operator is implemented in C++ using the
torch::autograd::Function class and compiled. At execution time, the Just-In-Time (JIT) compiler of Pytorch
is used to speed-up the computation.
For Pytorch version &lt; 1.3.0, the STE operator is implemented using the
torch.autograd.Function class in python, and the JIT cannot be used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Tensor on which to apply the ternary operation</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor after applying ternary operation. When backpropagating through this value,
a straight through estimator is applied.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-brevitas.function.shape">
<span id="brevitas-function-shape-module"></span><h2>brevitas.function.shape module<a class="headerlink" href="#module-brevitas.function.shape" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-brevitas.function">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-brevitas.function" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Alessandro Pappalardo

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>