convert_layernorm_to_rmsnorm: false
dataset: wikitext2
dtype: float32
eval: true
model: HuggingfaceTB/SmolLM2-135M
optimize_rotations: true
replace_rmsnorm: true
rotation: fused_no_fx
rotation_sdpa_regions: true
rotation_mode: had
rotation_orphan_sink: true
weight_bit_width: 3
weight_quant_format: int
weight_quant_granularity: per_group
weight_quant_type: sym
weight_scale_precision: float_scale
# HuggingFace TrainerArguments
learning_rate: 1.5
weight_decay: 0.0
lr_scheduler_type: cosine
max_steps: 100
save_safetensors: false
per_device_train_batch_size: 2
logging_steps: 10
gradient_accumulation_steps: 4
log_on_each_node: false
use_distillation_loss: true