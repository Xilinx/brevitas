arc_challenge_acc,none: 0.22610921501706485
arc_challenge_acc_norm,none: 0.25
arc_challenge_acc_norm_stderr,none: 0.012653835621466646
arc_challenge_acc_stderr,none: 0.012224202097063337
arc_easy_acc,none: 0.31565656565656564
arc_easy_acc_norm,none: 0.2946127946127946
arc_easy_acc_norm_stderr,none: 0.009354224395837286
arc_easy_acc_stderr,none: 0.009537019245566315
brevitas_version: 0.11.1.dev108+gabeacd50.d20250312
elapsed_time: 3240.713641166687
float_ppl: 13.738974571228027
piqa_acc,none: 0.5636561479869423
piqa_acc_norm,none: 0.5489662676822633
piqa_acc_norm_stderr,none: 0.011609747200732922
piqa_acc_stderr,none: 0.011570895640553759
quant_ppl: 38.15379333496094
retry_number: 1
status: successful
torch_version: 2.4.1+cu121
winogrande_acc,none: 0.5027624309392266
winogrande_acc_stderr,none: 0.014052271211616401
