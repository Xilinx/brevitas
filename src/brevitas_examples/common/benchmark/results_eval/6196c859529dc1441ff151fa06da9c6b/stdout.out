Model loading...
Model loaded.
Data loaded.
Float model eval...
{0: 14641685811.199999, 'cpu': 66768548761.6}
{'': 538060160, 'model': 538060160, 'model.embed_tokens': 113246208, 'model.embed_tokens.weight': 113246208, 'model.layers': 424811520, 'model.layers.0': 14160384, 'model.layers.1': 14160384, 'model.layers.2': 14160384, 'model.layers.3': 14160384, 'model.layers.4': 14160384, 'model.layers.5': 14160384, 'model.layers.6': 14160384, 'model.layers.7': 14160384, 'model.layers.8': 14160384, 'model.layers.9': 14160384, 'model.layers.10': 14160384, 'model.layers.11': 14160384, 'model.layers.12': 14160384, 'model.layers.13': 14160384, 'model.layers.14': 14160384, 'model.layers.15': 14160384, 'model.layers.16': 14160384, 'model.layers.17': 14160384, 'model.layers.18': 14160384, 'model.layers.19': 14160384, 'model.layers.20': 14160384, 'model.layers.21': 14160384, 'model.layers.22': 14160384, 'model.layers.23': 14160384, 'model.layers.24': 14160384, 'model.layers.25': 14160384, 'model.layers.26': 14160384, 'model.layers.27': 14160384, 'model.layers.28': 14160384, 'model.layers.29': 14160384, 'model.norm': 2304, 'model.norm.weight': 2304, 'model.rotary_emb': 128, 'model.rotary_emb.inv_freq': 128}
Float perplexity (wikitext2): 13.739
Applying model quantization...
Model quantization applied.
{0: 14641685811.199999, 'cpu': 66877106687.99999}
{'': 656250032, 'model': 543003824, 'model.embed_tokens': 114573312, 'model.embed_tokens.parametrizations': 114573312, 'model.layers': 428428080, 'model.layers.0': 14280936, 'model.layers.1': 14280936, 'model.layers.2': 14280936, 'model.layers.3': 14280936, 'model.layers.4': 14280936, 'model.layers.5': 14280936, 'model.layers.6': 14280936, 'model.layers.7': 14280936, 'model.layers.8': 14280936, 'model.layers.9': 14280936, 'model.layers.10': 14280936, 'model.layers.11': 14280936, 'model.layers.12': 14280936, 'model.layers.13': 14280936, 'model.layers.14': 14280936, 'model.layers.15': 14280936, 'model.layers.16': 14280936, 'model.layers.17': 14280936, 'model.layers.18': 14280936, 'model.layers.19': 14280936, 'model.layers.20': 14280936, 'model.layers.21': 14280936, 'model.layers.22': 14280936, 'model.layers.23': 14280936, 'model.layers.24': 14280936, 'model.layers.25': 14280936, 'model.layers.26': 14280936, 'model.layers.27': 14280936, 'model.layers.28': 14280936, 'model.layers.29': 14280936, 'model.norm': 2304, 'model.norm.weight': 2304, 'lm_head': 113246208, 'lm_head.parametrizations': 113246208, 'lm_head.parametrizations.weight': 113246208, 'model.rotary_emb': 128, 'model.rotary_emb.inv_freq': 128}
{'loss': 7.3654, 'grad_norm': 26.002159118652344, 'learning_rate': 0.4877641290737884, 'epoch': 0.1}
{'loss': 5.4745, 'grad_norm': 18.184890747070312, 'learning_rate': 0.45225424859373686, 'epoch': 0.2}
{'loss': 4.8415, 'grad_norm': 15.275945663452148, 'learning_rate': 0.3969463130731183, 'epoch': 0.3}
{'loss': 4.6469, 'grad_norm': 12.981037139892578, 'learning_rate': 0.32725424859373686, 'epoch': 0.4}
{'loss': 4.4303, 'grad_norm': 11.545337677001953, 'learning_rate': 0.25, 'epoch': 0.5}
{'loss': 4.3136, 'grad_norm': 11.06339168548584, 'learning_rate': 0.17274575140626316, 'epoch': 0.6}
{'loss': 4.2484, 'grad_norm': 10.754749298095703, 'learning_rate': 0.10305368692688174, 'epoch': 0.7}
{'loss': 4.2743, 'grad_norm': 9.916028022766113, 'learning_rate': 0.047745751406263165, 'epoch': 0.8}
{'loss': 4.2516, 'grad_norm': 9.86014175415039, 'learning_rate': 0.012235870926211617, 'epoch': 0.9}
{'loss': 4.2446, 'grad_norm': 10.399417877197266, 'learning_rate': 0.0, 'epoch': 1.0}
{'train_runtime': 785.2174, 'train_samples_per_second': 1.019, 'train_steps_per_second': 0.127, 'train_loss': 4.809089813232422, 'epoch': 1.0}
{0: 14870694809.599998, 'cpu': 66693901209.6}
{'': 656250032, 'model': 543003824, 'model.embed_tokens': 114573312, 'model.embed_tokens.parametrizations': 114573312, 'model.layers': 428428080, 'model.layers.0': 14280936, 'model.layers.1': 14280936, 'model.layers.2': 14280936, 'model.layers.3': 14280936, 'model.layers.4': 14280936, 'model.layers.5': 14280936, 'model.layers.6': 14280936, 'model.layers.7': 14280936, 'model.layers.8': 14280936, 'model.layers.9': 14280936, 'model.layers.10': 14280936, 'model.layers.11': 14280936, 'model.layers.12': 14280936, 'model.layers.13': 14280936, 'model.layers.14': 14280936, 'model.layers.15': 14280936, 'model.layers.16': 14280936, 'model.layers.17': 14280936, 'model.layers.18': 14280936, 'model.layers.19': 14280936, 'model.layers.20': 14280936, 'model.layers.21': 14280936, 'model.layers.22': 14280936, 'model.layers.23': 14280936, 'model.layers.24': 14280936, 'model.layers.25': 14280936, 'model.layers.26': 14280936, 'model.layers.27': 14280936, 'model.layers.28': 14280936, 'model.layers.29': 14280936, 'model.norm': 2304, 'model.norm.weight': 2304, 'lm_head': 113246208, 'lm_head.parametrizations': 113246208, 'lm_head.parametrizations.weight': 113246208, 'model.rotary_emb': 128, 'model.rotary_emb.inv_freq': 128}
Model eval...
Quantized perplexity (wikitext2): 47.348
Few shot eval results
{'arc_challenge_acc,none': 0.23208191126279865,
 'arc_challenge_acc_norm,none': 0.2380546075085324,
 'arc_challenge_acc_norm_stderr,none': 0.012445770028026118,
 'arc_challenge_acc_stderr,none': 0.012336718284948816,
 'arc_easy_acc,none': 0.30934343434343436,
 'arc_easy_acc_norm,none': 0.28914141414141414,
 'arc_easy_acc_norm_stderr,none': 0.009302827114597558,
 'arc_easy_acc_stderr,none': 0.009484615220606778,
 'piqa_acc,none': 0.5538628944504896,
 'piqa_acc_norm,none': 0.5364526659412405,
 'piqa_acc_norm_stderr,none': 0.01163477983787243,
 'piqa_acc_stderr,none': 0.011597936590301249,
 'winogrande_acc,none': 0.5153906866614049,
 'winogrande_acc_stderr,none': 0.014045826789783585}
