arc_challenge_acc,none: 0.22866894197952217
arc_challenge_acc_norm,none: 0.2525597269624573
arc_challenge_acc_norm_stderr,none: 0.012696728980207687
arc_challenge_acc_stderr,none: 0.012272853582540892
arc_easy_acc,none: 0.2702020202020202
arc_easy_acc_norm,none: 0.2786195286195286
arc_easy_acc_norm_stderr,none: 0.009199329195026532
arc_easy_acc_stderr,none: 0.009112002229119622
brevitas_version: 0.11.1.dev108+gabeacd50.d20250312
elapsed_time: 3015.5765459537506
float_ppl: 13.738974571228027
piqa_acc,none: 0.5402611534276387
piqa_acc_norm,none: 0.5201305767138193
piqa_acc_norm_stderr,none: 0.011656365410780507
piqa_acc_stderr,none: 0.011627942981817204
quant_ppl: 150.272705078125
retry_number: 1
status: successful
torch_version: 2.4.1+cu121
winogrande_acc,none: 0.5035516969218626
winogrande_acc_stderr,none: 0.014052131146915852
