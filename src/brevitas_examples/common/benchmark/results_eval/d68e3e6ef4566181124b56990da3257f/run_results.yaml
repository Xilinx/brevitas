arc_challenge_acc,none: 0.22781569965870307
arc_challenge_acc_norm,none: 0.25
arc_challenge_acc_norm_stderr,none: 0.012653835621466646
arc_challenge_acc_stderr,none: 0.012256708602326964
arc_easy_acc,none: 0.31186868686868685
arc_easy_acc_norm,none: 0.2946127946127946
arc_easy_acc_norm_stderr,none: 0.009354224395837286
arc_easy_acc_stderr,none: 0.009505823345817531
brevitas_version: 0.11.1.dev108+gabeacd50.d20250312
elapsed_time: 3202.6459572315216
float_ppl: 13.738974571228027
piqa_acc,none: 0.5609357997823722
piqa_acc_norm,none: 0.5571273122959739
piqa_acc_norm_stderr,none: 0.011589430503509043
piqa_acc_stderr,none: 0.01157886564932124
quant_ppl: 38.27146530151367
retry_number: 1
status: successful
torch_version: 2.4.1+cu121
winogrande_acc,none: 0.505130228887135
winogrande_acc_stderr,none: 0.014051745961790525
