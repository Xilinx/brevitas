arc_challenge_acc,none: 0.22184300341296928
arc_challenge_acc_norm,none: 0.257679180887372
arc_challenge_acc_norm_stderr,none: 0.012780770562768334
arc_challenge_acc_stderr,none: 0.012141659068148035
arc_easy_acc,none: 0.30008417508417506
arc_easy_acc_norm,none: 0.29124579124579125
arc_easy_acc_norm_stderr,none: 0.009322788837939095
arc_easy_acc_stderr,none: 0.009404000558513162
brevitas_version: 0.11.1.dev108+gabeacd50.d20250312
elapsed_time: 3280.4861419200897
float_ppl: 13.738974571228027
piqa_acc,none: 0.5603917301414582
piqa_acc_norm,none: 0.5331882480957563
piqa_acc_norm_stderr,none: 0.011640096923563308
piqa_acc_stderr,none: 0.011580417248656388
quant_ppl: 39.70476150512695
retry_number: 1
status: successful
torch_version: 2.4.1+cu121
winogrande_acc,none: 0.4972375690607735
winogrande_acc_stderr,none: 0.014052271211616401
