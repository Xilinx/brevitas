arc_challenge_acc,none: 0.21416382252559726
arc_challenge_acc_norm,none: 0.24829351535836178
arc_challenge_acc_norm_stderr,none: 0.012624912868089679
arc_challenge_acc_stderr,none: 0.011988383205966574
arc_easy_acc,none: 0.2828282828282828
arc_easy_acc_norm,none: 0.2798821548821549
arc_easy_acc_norm_stderr,none: 0.009212077524656682
arc_easy_acc_stderr,none: 0.009241472775328163
brevitas_version: 0.11.1.dev108+gabeacd50.d20250312
elapsed_time: 3019.916162967682
float_ppl: 13.738974571228027
piqa_acc,none: 0.5408052230685527
piqa_acc_norm,none: 0.5206746463547334
piqa_acc_norm_stderr,none: 0.011655846995729838
piqa_acc_stderr,none: 0.011626910523588394
quant_ppl: 137.8856201171875
retry_number: 1
status: successful
torch_version: 2.4.1+cu121
winogrande_acc,none: 0.4956590370955012
winogrande_acc_stderr,none: 0.014051956064076884
