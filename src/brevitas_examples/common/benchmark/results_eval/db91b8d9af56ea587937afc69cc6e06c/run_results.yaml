arc_challenge_acc,none: 0.2235494880546075
arc_challenge_acc_norm,none: 0.2440273037542662
arc_challenge_acc_norm_stderr,none: 0.012551447627856151
arc_challenge_acc_stderr,none: 0.012174896631202666
arc_easy_acc,none: 0.2760942760942761
arc_easy_acc_norm,none: 0.281986531986532
arc_easy_acc_norm_stderr,none: 0.009233124071053615
arc_easy_acc_stderr,none: 0.00917355987383544
brevitas_version: 0.11.1.dev108+gabeacd50.d20250312
elapsed_time: 3026.2125153541565
float_ppl: 13.738974571228027
piqa_acc,none: 0.544069640914037
piqa_acc_norm,none: 0.5310119695321001
piqa_acc_norm_stderr,none: 0.011643363511107561
piqa_acc_stderr,none: 0.011620422647622046
quant_ppl: 137.4764862060547
retry_number: 1
status: successful
torch_version: 2.4.1+cu121
winogrande_acc,none: 0.47908445146014206
winogrande_acc_stderr,none: 0.014040185494212999
