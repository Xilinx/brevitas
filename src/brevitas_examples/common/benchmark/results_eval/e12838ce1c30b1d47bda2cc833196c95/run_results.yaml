arc_challenge_acc,none: 0.22781569965870307
arc_challenge_acc_norm,none: 0.25426621160409557
arc_challenge_acc_norm_stderr,none: 0.012724999945157845
arc_challenge_acc_stderr,none: 0.012256708602326964
arc_easy_acc,none: 0.3244949494949495
arc_easy_acc_norm,none: 0.2988215488215488
arc_easy_acc_norm_stderr,none: 0.009392656275408704
arc_easy_acc_stderr,none: 0.009606970654515608
brevitas_version: 0.11.1.dev108+gabeacd50.d20250312
elapsed_time: 3069.2048959732056
float_ppl: 13.738974571228027
piqa_acc,none: 0.5571273122959739
piqa_acc_norm,none: 0.5424374319912949
piqa_acc_norm_stderr,none: 0.011623729421517952
piqa_acc_stderr,none: 0.011589430503509043
quant_ppl: 43.156158447265625
retry_number: 1
status: successful
torch_version: 2.4.1+cu121
winogrande_acc,none: 0.49329123914759276
winogrande_acc_stderr,none: 0.014051220692330247
